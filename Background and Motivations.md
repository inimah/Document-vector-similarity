
Motivations: 
Human (sometimes - not in all cases) can easily retrieve useful information from documents or categorizing documents by looking at the contextual meaning of  words in a document, for instance. This includes processes in finding association / semantic meaning between words or documents in a natural way (through the long process of learning language since the time we were taught to read and speak). Computer, however, only understands mathematical function. Some computational approaches of Natural Language Processing also need heuristic rules and human annotation beforehands - which is mostly labour expensive and time consuming. This creates challenges in word-language modelling, such as:
- how to extract useful features (e.g. word vector representation) from the unstructured document, by only using mathematical ?
- how to find (hopefully) interesting pattern in the word-document clusters to be further evaluated with the original class label (if anys)

The different (and connection!) with previous studies???:
- focus on unsupervised approach (clustering)
- document-to-document level similarity, instead of word level similarity
- similarity metric distance for high dimensionality vector (since each word vector of WE represents n-dimensional vector, n depends on number of neurons used in training the word embedding)
